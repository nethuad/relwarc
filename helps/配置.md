# crawler/tutorial/tutorial/settings.py
```
#不遵循robots协议
ROBOTSTXT_OBEY = False

#设置请求头信息，伪造浏览器headers，手动添加一个user-agent
DEFAULT_REQUEST_HEADERS = {
  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
  'Accept-Language': 'zh-CN,zh;q=0.9',
  'User-Agent': "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"
}

DOWNLOAD_DELAY=30  # 延迟30秒

RANDOMIZE_DOWNLOAD_DELAY = True # 默认
```


UserAgent 默认为：Scrapy/1.5.0 (+https://scrapy.org)

# 查看配置信息
在项目文件夹下运行
scrapy settings  --get=DEFAULT_REQUEST_HEADERS
scrapy settings  --get=DOWNLOAD_DELAY
scrapy settings  --get=RANDOMIZE_DOWNLOAD_DELAY


# 如何访问设定(How to access settings)
设定可以通过Crawler的 scrapy.crawler.Crawler.settings 属性进行访问。其由插件及中间件的 from_crawler 方法所传入:

class MyExtension(object):

    @classmethod
    def from_crawler(cls, crawler):
        settings = crawler.settings
        if settings['LOG_ENABLED']:
            print "log is enabled!"
